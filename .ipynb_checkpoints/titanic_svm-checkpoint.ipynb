{
 "metadata": {
  "language": "Julia",
  "name": "",
  "signature": "sha256:a3ac8f3c33f106bfac4d4cb61c2311b43b9959bab009a4244f7e3b944605f7f9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Predicting Titanic Survival with Support Vector Machines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using DataFrames, RegERMs, MLBase"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"/Users/nicklawler222/ml_julia/kaggle/kaggle_titanic\"\n",
      "test  = readtable(\"$(path)/data/test.csv\");\n",
      "train = readtable(\"$(path)/data/train.csv\");\n",
      "n,m = size(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initial Attempt: SVM with Age and Sex, rbf kernel, no cv or parameter tuning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The RegERMs package is very new, and doesn't support Dataframes. Fortunately, we can still use them to clean and alter the data, and then use the handy array() function to get it into a pretty matrix. Lets perform the same transformations that we used in the previous tutorial"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# adds a row to df named new_row at index, which is a binary represenation of old_row where old_row[i] == positive_class\n",
      "function df_string_to_binary!(df::DataFrame, index::Int64, old_row::Symbol, new_row::Symbol, positive_class::Any )\n",
      "    insert!(df, index, int(df[old_row] .== positive_class), new_row)\n",
      "end\n",
      "\n",
      "# used exclusively for this dataset, replaces all the NA values in Age with the overall median age\n",
      "function replace_na_median!(df::DataFrame)\n",
      "    # get the indices of NA and non NA rows\n",
      "    na_indicator = isna(df[:Age])\n",
      "    filled_indices, na_indices = [] , []\n",
      "    for i in 1:size(na_indicator,1)\n",
      "        if !na_indicator[i]\n",
      "            filled_indices = [filled_indices, i]\n",
      "        else\n",
      "            na_indices = [na_indices, i]\n",
      "        end\n",
      "    end\n",
      "    \n",
      "    # get the median of non-NA rows\n",
      "    median_age = median(df[:Age][filled_indices])\n",
      "\n",
      "    # Insert a new dataframe row with that value substituting for NA's\n",
      "    adjustedAge = copy(df[:Age])\n",
      "    adjustedAge[na_indices] = median_age\n",
      "    insert!(df, 8, adjustedAge, :AdjustedAge)\n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_string_to_binary!(train, 6, :Sex, :SexBinary, \"male\")\n",
      "replace_na_median!(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_string_to_binary!(test, 5, :Sex, :SexBinary, \"male\")\n",
      "replace_na_median!(test)\n",
      "fare_na_index = sum(isna(test[:Fare]) .* [1:size(test[:Fare],1)])\n",
      "test[:Fare][fare_na_index] = median(dropna(test[:Fare]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "RegERMs requires 1 and -1 for positive and negative classes, so we'll switch all those 0's to -1's and set up the SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = float(array(train[[:SexBinary, :AdjustedAge]])) # cast to float so optimizer doesn't complain\n",
      "y = array(train[:Survived])\n",
      "y = [label == 1 ? 1 : -1 for label in y];"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age_sex_svm_rbf = SVM(X,y; kernel = :rbf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll set a regularization parameter for this initial test and optimize it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regParam = 0.1\n",
      "@time model = optimize(age_sex_svm_rbf, regParam)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets take a quick look at the training error"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yhat = int(predict(model, X)) # output is in the type of X, must cast back to int\n",
      "error_train = correctrate(y, ybar)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets do the whole shebang on the test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = float(array(test[[:SexBinary, :AdjustedAge]]));\n",
      "yhat = int(predict(model, X_test))\n",
      "yhat = [label == 1 ? 1 : 0 for label in ybar] # get labels back into {0, 1}\n",
      "\n",
      "submission = DataFrame()\n",
      "submission[:PassengerId] = test[:PassengerId]\n",
      "submission[:Survived] = yhat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Submission 1 Leaderboard Score: 0.68900 "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Second Attempt: Same Data, Now with feature scaling and model parameters tuned on cross validation accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets do a quick comparison to see how feature scaling affects training time and performance relative to not having it. We'll do the previous calculations over again to compare the time, but we'll only submit the results for the feature scaled version"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function scale_features!(X::Array{Float64,2})\n",
      "    n, m = size(X)\n",
      "    for i = 1:m\n",
      "        feature_mean = mean(X[:,i])\n",
      "        feature_std = std(X[:, i])\n",
      "        \n",
      "        X[:, i] = X[:, i] .- feature_mean\n",
      "        X[:, i] = X[:, i] ./ feature_std\n",
      "    end\n",
      "end\n",
      "\n",
      "function scale_features(X::Array{Float64,2}) \n",
      "    Q = copy(X)\n",
      "    scale_features!(Q)\n",
      "    return Q\n",
      "end\n",
      "\n",
      "X_fs = scale_features(X);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = [label == 1 ? 1 : -1 for label in y]\n",
      "@time svm = SVM(X,y; kernel = :rbf)\n",
      "@time svm_fs = SVM(X_fs,y; kernel = :rbf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = 0.1\n",
      "@time model = optimize(svm, C)\n",
      "@time model_fs = optimize(svm_fs, C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = float(array(test[[:SexBinary, :AdjustedAge]]))\n",
      "ybar_fs = float(predict(model_fs, X_test))\n",
      "ybar_fs = [label == 1 ? 1 : 0 for label in ybar_fs]; # get labels back into {0, 1}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission[:Survived] = ybar_fs\n",
      "submission"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Submission 2 Score: 0.64593 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, we gain some training speed at the expense of some accuracy. We should be able to minimize the loss of accuracy when we tune the parameter C"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Sumbission 3: Tuning Regularization parameter with 3-Fold Cross Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets test out the cross validation function first, we'll be using a 3-fold CV"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@time score = mean(cross_validate(\n",
      "    inds -> optimize(SVM(X_fs[inds, :], y[inds]; kernel = :rbf), C), #returns a learned model\n",
      "    (c, inds) -> correctrate( int(predict(c, X_fs[inds, :])), y[inds]), # evaluates cv error\n",
      "    n, \n",
      "    Kfold(n,3)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since everything seems to be working, we'll use this score in our model tuning function, as we try out different values of the regularization parameter C. The RBF Kernel has another parameter sigma, but unfortunately RegERMs doesn't provide a parameterization of sigma. I made some early attempts to hack that functionality into the package's interface, but I soon realized it would have taken too much time to get it working properly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C_values = 10 .^ [-4.0:1.0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function estfun(C)\n",
      "    return C\n",
      "end\n",
      "\n",
      "function evalfun(C)\n",
      "    score = mean(cross_validate(\n",
      "        inds -> optimize(SVM(X_fs[inds, :], y[inds]; kernel = :rbf), C), #returns a learned model\n",
      "        (c, inds) -> correctrate( y[inds], int(predict(c, X_fs[inds, :]))), # evaluates cv error\n",
      "        n, \n",
      "        Kfold(n,3))\n",
      "    )\n",
      "    return score\n",
      "end\n",
      "@time r = gridtune(estfun, evalfun,\n",
      "    (\"C\", C_values);\n",
      "    ord=Forward,\n",
      "    verbose=true)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gridtune returns the configuration of parmeter settings that gives the highest score. Since we're only tuning one parameter, it simply returns the optimal value of C. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we add more data to the training set, we need a way of one-hot encoding the categorical variable \"Embarked\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function one_hot_encode!(df::DataFrame, Row::Symbol, domain::Array)\n",
      "    # have to handle NA's\n",
      "    for value in domain\n",
      "        one_hot = zeros(size(df,1))\n",
      "        for i = 1:size(df,1)\n",
      "            if df[Row][i] == value\n",
      "                one_hot[i] = 1\n",
      "            end\n",
      "        end\n",
      "        NewRow = symbol(string(Row) * string(value)) # \"$(Row)$(value)\"\n",
      "        df[NewRow] = one_hot\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It turns out that there are also some NA's in Embarked that we need to get rid of"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function get_na_indices(arr::DataArray)\n",
      "    na_indices = zeros(sum(isna(arr))) # allocate array big enough for al NA's\n",
      "    j = 1\n",
      "    for i = 1:size(arr,1)\n",
      "        if isna(arr[i])\n",
      "            na_indices[j] = i\n",
      "            j += 1\n",
      "        end\n",
      "    end\n",
      "    return int(na_indices)\n",
      "end\n",
      "\n",
      "na_indices = get_na_indices(train[:Embarked])\n",
      "train[:Embarked][na_indices] = \"S\" # I remember reading that most people embarked from S"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_hot_encode!(train, :Embarked,[\"S\", \"C\", \"Q\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, time to put some more data into play"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construct new X matrix\n",
      "\n",
      "X = array(train[[:Pclass, :AdjustedAge, :SexBinary, :SibSp, :Parch, :Fare, :EmbarkedS, :EmbarkedC, :EmbarkedQ]])\n",
      "X = float(X)\n",
      "scale_features!(X)\n",
      "\n",
      "\n",
      "# reconstruct y for posterity\n",
      "y = [label == 1 ? 1 : -1 for label in array(train[:Survived])]\n",
      "\n",
      "# train and cross validate models\n",
      "function estfun(C)\n",
      "    return C\n",
      "end\n",
      "\n",
      "function evalfun(C)\n",
      "    score = mean(cross_validate(\n",
      "        inds -> optimize(SVM(X[inds, :], y[inds]; kernel = :rbf), C), #returns a learned model\n",
      "        (c, inds) -> correctrate( y[inds], int(predict(c, X[inds, :]))), # evaluates cv error\n",
      "        n, \n",
      "        Kfold(n,3)))\n",
      "    return score\n",
      "end\n",
      "@time r = gridtune(estfun, evalfun,\n",
      "    (\"C\", C_values);\n",
      "    ord=Forward,\n",
      "    verbose=true)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train model with C = 0.0001 with all data\n",
      "C = r[1]\n",
      "svm = SVM(X, y; kernel = :rbf)\n",
      "model = optimize(svm, C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# one hot encode Embarked for test set\n",
      "one_hot_encode!(test, :Embarked,[\"S\", \"C\", \"Q\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare test set\n",
      "X_test = float(array(test[[:Pclass, :AdjustedAge, :SexBinary, :SibSp, :Parch, :Fare, :EmbarkedS, :EmbarkedC, :EmbarkedQ]]))\n",
      "scale_features!(X_test)\n",
      "\n",
      "# make predictions, get results back into proper domain\n",
      "ybar = predict(model, X_test)\n",
      "ybar = [label == 1 ? 1 : 0 for label in ybar]; \n",
      "\n",
      "# setup submission\n",
      "submission = DataFrame()\n",
      "submission[:PassengerId] = test[:PassengerId]\n",
      "submission[:Survived] = ybar"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "writetable(\"$(path)/submissions/titanic_svm_3.csv\", submission)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Submission 3 Score: 0.74163 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is fairly good considering I wasn't able to tune the sigma parameter as I would have liked to. I'm confident that if RegERMs had that feature, I would have been able to beat my linear regression score of. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}